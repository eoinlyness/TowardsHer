{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"collab_privacy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.8 64-bit","metadata":{"interpreter":{"hash":"57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"}}},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8-final"}},"cells":[{"cell_type":"code","metadata":{"id":"MDUHl-wDwElx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617194875450,"user_tz":-60,"elapsed":624,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}},"outputId":"45cf45be-b726-4649-9626-f1825d8e5039"},"source":["#\n","# Author: Eoin Lyness\n","# Train collaborative filtering model (privacy-preserving)\n","#\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import torch.optim as optim\n","import syft as sy\n","import time\n","from torch.utils.data import Dataset\n","from syft.frameworks.torch.fl import utils\n","import random\n","from copy import deepcopy\n","from torch.utils.data import DataLoader, Dataset\n","\n","random.seed(4006)\n","hook = sy.TorchHook(torch)\n","class Arguments():\n","    def __init__(self):\n","        self.batch_size = 64\n","        self.test_batch_size = 64\n","        self.seed = 4006"],"execution_count":39,"outputs":[{"output_type":"stream","text":["WARNING:root:Torch was already hooked... skipping hooking process\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vUVo8n5WsA6I","executionInfo":{"status":"ok","timestamp":1617194878384,"user_tz":-60,"elapsed":917,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["class UserItemRatingDataset(Dataset):\n","    \"\"\"Wrapper, convert <user, item, rating> Tensor into Pytorch Dataset\"\"\"\n","    def __init__(self, user_tensor, item_tensor, target_tensor):\n","        \"\"\"\n","        args:\n","            target_tensor: torch.Tensor, the corresponding rating for <user, item> pair\n","        \"\"\"\n","        self.user_tensor = user_tensor\n","        self.item_tensor = item_tensor\n","        self.target_tensor = target_tensor\n"," \n","    def __getitem__(self, index):\n","        data_tensor=torch.stack([self.user_tensor[index], self.item_tensor[index]],dim=0)\n","        return data_tensor, self.target_tensor[index]\n"," \n","    def __len__(self):\n","        return len(self.user_tensor)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJrjiE9n4USa","executionInfo":{"status":"ok","timestamp":1617194881465,"user_tz":-60,"elapsed":889,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["#Load dataset\n","fname = 'output/cluster_out.csv'\n","data = pd.read_csv(fname, index_col=0)\n","\n","#Split data into 80:20 training:validation\n","train_data = data.sample(frac=0.8)\n","train_data = train_data.reset_index(drop=True)\n","\n","test_data = data.sample(frac=0.2)\n","test_data = test_data.reset_index(drop=True)\n","\n","#Process dataset attributes to prepare for use with model:\n","#Map each user to a unique ID\n","#Cast cluster and mood to type float \n","user_ids = train_data[\"user\"].unique().tolist()\n","cluster_ids = train_data[\"cluster\"].unique().tolist()\n","num_users = len(user_ids)\n","num_clusters = len(cluster_ids)\n","\n","user_map = {x: i for i, x in enumerate(user_ids)}\n","train_data[\"user\"] = train_data[\"user\"].map(user_map)\n","train_data[\"cluster\"] = train_data[\"cluster\"].values.astype(np.float32)\n","train_data[\"mood\"] = train_data[\"mood\"].values.astype(np.float32)\n","\n","test_user_ids = test_data[\"user\"].unique().tolist()\n","test_cluster_ids = test_data[\"cluster\"].unique().tolist()\n","test_num_users = len(test_user_ids)\n","test_num_clusters = len(test_cluster_ids)\n","\n","test_user_map = {x: i for i, x in enumerate(test_user_ids)}\n","test_data[\"user\"] = test_data[\"user\"].map(test_user_map)\n","test_data[\"cluster\"] = test_data[\"cluster\"].values.astype(np.float32)\n","test_data[\"mood\"] = test_data[\"mood\"].values.astype(np.float32)\n"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPhk5DiXE1Cb","executionInfo":{"status":"ok","timestamp":1617194896460,"user_tz":-60,"elapsed":12981,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["#Create virtual workers\n","\n","workers = []\n","\n","for user_id in user_ids:\n","    worker = sy.VirtualWorker(hook, id=\"user_\"+str(user_id))\n","    workers.append(worker)\n","\n","#Create federated data loader for training data\n","federated_train_loader = sy.FederatedDataLoader(\n","UserItemRatingDataset(torch.LongTensor(train_data[\"user\"]),torch.LongTensor(train_data[\"cluster\"]),torch.FloatTensor(train_data[\"mood\"])).federate(tuple(workers)),batch_size=64,shuffle=True,iter_per_worker=True)\n","\n","kwargs = {}\n","\n","#Create data loaders to validate the training and validation data\n","train_test_loader = torch.utils.data.DataLoader(\n","UserItemRatingDataset(torch.LongTensor(train_data[\"user\"]),torch.LongTensor(train_data[\"cluster\"]),torch.FloatTensor(train_data[\"mood\"])),batch_size=64,shuffle=True, **kwargs)\n","\n","valid_test_loader = torch.utils.data.DataLoader(\n","UserItemRatingDataset(torch.LongTensor(test_data[\"user\"]),torch.LongTensor(test_data[\"cluster\"]),torch.FloatTensor(test_data[\"mood\"])),batch_size=64,shuffle=True, **kwargs)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUH2RBnISmIo","executionInfo":{"status":"ok","timestamp":1617194900439,"user_tz":-60,"elapsed":1304,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["#Define the model\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.num_users = num_users\n","        self.num_movies = num_clusters\n","        self.embedding_size = embedding_size\n","        \n","        self.user_embedding = nn.Embedding(num_users, embedding_size)\n","        self.movie_embedding = nn.Embedding(num_clusters, embedding_size)\n","        \n","        self.fc_layers = nn.ModuleList()\n","        self.fc_layers.append(nn.Linear(50, 50))\n","        self.output_layer = nn.Linear(embedding_size, 1)\n","\n","    def forward(self, train_data):\n","        users = torch.as_tensor(train_data[:,0])\n","        movies = torch.as_tensor(train_data[:,1])\n","        user_embedding_x = self.user_embedding(users)\n","        movie_embedding_y = self.movie_embedding(movies)\n","        prod=torch.mul(user_embedding_x,movie_embedding_y)\n","        \n","        logit = self.output_layer(prod)\n","        return logit\n","\n","    def predict(self, train_data):\n","        return self.forward(train_data)\n"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"GalDOGKExaHt","executionInfo":{"status":"ok","timestamp":1617194904677,"user_tz":-60,"elapsed":1403,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["def train_on_batches(worker, batches, model_in, device, lr):\n","    \"\"\"Train the model on the worker on the provided batches\n","    Args:\n","        worker(syft.workers.BaseWorker): worker on which the\n","        training will be executed\n","        batches: batches of data of this worker\n","        model_in: machine learning model, training will be done on a copy\n","        device (torch.device): where to run the training\n","        lr: learning rate of the training steps\n","    Returns:\n","        model, loss: obtained model and loss after training\n","    \"\"\"\n","    model = model_in.copy()\n","    optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","    model.train()\n","    model.send(worker)\n","    loss_local = False\n","    LOG_INTERVAL=len(batches)\n","\n","    for batch_idx, (data, target) in enumerate(batches):\n","        loss_local = False\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = f.mse_loss(output.view(-1), target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % LOG_INTERVAL == 0:\n","            loss = loss.get()\n","            loss_local = True\n","\n","    if not loss_local:\n","      loss = loss.get()\n","    model.get()\n","    return model, loss\n","\n","\n","def get_next_batches(fdataloader: sy.FederatedDataLoader, nr_batches: int):\n","    \"\"\"retrieve next nr_batches of the federated data loader and group\n","    the batches by worker\n","    Args:\n","        fdataloader (sy.FederatedDataLoader): federated data loader\n","        over which the function will iterate\n","        nr_batches (int): number of batches (per worker) to retrieve\n","    Returns:\n","        Dict[syft.workers.BaseWorker, List[batches]]\n","    \"\"\"\n","    batches = {}\n","    for worker_id in fdataloader.workers:\n","        worker = fdataloader.federated_dataset.datasets[worker_id].location\n","        batches[worker] = []\n","    try:\n","        for i in range(nr_batches):\n","            next_batches = next(fdataloader)\n","            for worker in next_batches:\n","                batches[worker].append(next_batches[worker])\n","    except StopIteration:\n","        pass\n","    return batches\n","\n","\n","def train(\n","    model, device, federated_train_loader, lr, federate_after_n_batches, abort_after_one=False\n","):\n","    model.train()\n","\n","    nr_batches = federate_after_n_batches\n","\n","    models = {}\n","    loss_values = {}\n","\n","    iter(federated_train_loader)  # initialize iterators\n","    batches = get_next_batches(federated_train_loader, nr_batches)\n","    counter = 0\n","\n","    while True:\n","        data_for_all_workers = True\n","        for worker in batches:\n","            curr_batches = batches[worker]\n","            if curr_batches:\n","                models[worker], loss_values[worker] = train_on_batches(\n","                    worker, curr_batches, model, device, lr\n","                )\n","            else:\n","                data_for_all_workers = False\n","        counter += nr_batches\n","        if not data_for_all_workers:\n","            break\n","        model = utils.federated_avg(models)\n","        batches = get_next_batches(federated_train_loader, nr_batches)\n","        if abort_after_one:\n","            break\n","\n","    return model\n"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"BX-bZVLv8CN9","executionInfo":{"status":"ok","timestamp":1617194914902,"user_tz":-60,"elapsed":847,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += f.mse_loss(output.view(-1), target, reduction='sum').item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    return test_loss"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPhZTPCi_sZv","executionInfo":{"status":"ok","timestamp":1617194917399,"user_tz":-60,"elapsed":610,"user":{"displayName":"Eoin Lyness","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhHy-0Qp2x89Yjs-gWqCAeHFyrbyNRbiokha03LQ=s64","userId":"02136857672783289318"}}},"source":["fname_out = 'output/collab_privacy_out.csv'\n","result = pd.DataFrame(columns=['epoch', 'train_loss', 'valid_loss', 'time'])"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRhwZABHxctO","scrolled":false,"tags":[]},"source":["#Define training parameters\n","embedding_size=50\n","model = Model()\n","lr = 0.1\n","batch_size = 64\n","federate_after_n_batches=round(len(train_data) / batch_size / len(workers))\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","device=torch.device(\"cpu\")\n","#Run training over 50 epochs\n","for epoch in range(1, 51):\n","        print(\"Starting epoch {}/{}\".format(epoch,50))\n","        #Train the model and record training time\n","        start = time.time()\n","        model = train(model, device, federated_train_loader, lr, federate_after_n_batches)\n","        stop = time.time()\n","        t = stop - start\n","\n","        #Calculate training and validation loss after training\n","        train_loss = test(model,device, train_test_loader)\n","        valid_loss = test(model, device, valid_test_loader)\n","        \n","        print('Training Time (s): {:.2f}, Train loss: {:.4f}, Valid loss: {:.4f}\\n'.format(t, train_loss, valid_loss))\n","\n","        result.loc[epoch-1] = [epoch, train_loss, valid_loss, t]\n","\n","#Output results to file\n","result.to_csv(fname_out)\n"],"execution_count":null,"outputs":[]}]}